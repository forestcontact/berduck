{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pytextrank\n",
    "import pandas as pd\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "nlp = spacy.load('en_core_web_md') \n",
    "\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob \n",
    "spacy_text_blob = SpacyTextBlob() \n",
    "nlp.add_pipe(spacy_text_blob) \n",
    "\n",
    "tr = pytextrank.TextRank()\n",
    "nlp.add_pipe(tr.PipelineComponent, name=\"textrank\", last=True)\n",
    "\n",
    "# from sense2vec import Sense2VecComponent\n",
    "# s2v = Sense2VecComponent(nlp.vocab).from_disk(\"/home/maze/Hacking/_datasets/s2v_old\")\n",
    "# nlp.add_pipe(s2v)\n",
    "\n",
    "df = pd.read_csv('emoji-faces.csv')\n",
    "# emoji_list = list(df[\"Char\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spacy_doc(text):\n",
    "    doc = nlp(text)\n",
    "    return(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For generating emoji through a simple sentiment-analysis grid\n",
    "def sympathize(doc): \n",
    "    neutrality = 1 - doc._.sentiment.subjectivity\n",
    "    return(doc._.sentiment.polarity, neutrality)\n",
    "\n",
    "def dist(coord, loc):\n",
    "    a = abs(coord[0]-loc[0])\n",
    "    b = abs(coord[1]-loc[1])\n",
    "    c = sqrt(a**2 + b**2)\n",
    "    return c\n",
    "\n",
    "def emote(doc, n=5):\n",
    "    coord = sympathize(doc)\n",
    "    #     print(coord)\n",
    "    distances = [(i, dist(coord, (row[\"Sentiment score\"], row[\"Neut\"]))) for i, row in df.iterrows()]\n",
    "    nearest = sorted(distances, key=lambda tup: tup[1])\n",
    "    emojis = pd.DataFrame([(df[\"Char\"][i], distance) for i, distance in nearest])\n",
    "    return(\"\".join([emoji for emoji in emojis[:n][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get emoji using sense2vec (huge download though)\n",
    "# def sim(char, doc):\n",
    "#     char_doc = make_spacy_doc(char)\n",
    "#     phrase_list = doc.s2v_phrases\n",
    "#     return(doc[0:-1]._.s2v_similarity(char_doc))\n",
    "\n",
    "# def emote(doc, n=5):\n",
    "#     distances = [(char, sim(char, doc)) for char in emoji_list]\n",
    "#     nearest = sorted(distances)\n",
    "#     return(nearest[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(tok, from_word=\"simple\", to_word=\"uncomplicated\", n=10):\n",
    "    tok_doc = make_spacy_doc(tok)\n",
    "    if tok_doc.vector is None:\n",
    "        return(\"something I don't know about\")\n",
    "    vec = tok_doc.vector - make_spacy_doc(from_word).vector #+ make_spacy_doc(to_word).vector\n",
    "#     vec = tok_doc.vector\n",
    "    vec_ids = nlp.vocab.vectors.most_similar(vec.reshape(1,vec.shape[0]), n=n)\n",
    "    new_toks = [nlp.vocab.strings[vec] for i, vec in enumerate(vec_ids[0][0])]\n",
    "    return(new_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crappy_sort(doc, memory, n=5):\n",
    "    if not doc._.phrases:\n",
    "        return \"...\"\n",
    "    thoughts = []\n",
    "    for p in doc._.phrases: \n",
    "        if p.text not in str(memory).lower():\n",
    "            for ent in doc.ents:\n",
    "                if ent.text.lower() in p.text:\n",
    "                    if ent.label_ == \"PERSON\" or ent.label_ == \"NORP\" or ent.label_ == \"ORG\":\n",
    "                        thoughts.append(f\"Who is {ent.text}?\")\n",
    "                    elif ent.label_ == \"GPE\" or ent.label_ == \"FAC\" or ent.label_ == \"LOC\": \n",
    "                        thoughts.append(f\"Where is {ent.text}?\")\n",
    "                    elif ent.label_ == \"DATE\" or ent.label_ == \"TIME\": \n",
    "                        thoughts.append(f\"When is {ent.text}?\")\n",
    "                    elif ent.label_ == \"PERCENT\" or ent.label_ == \"MONEY\"or ent.label_ == \"QUANTITY\": \n",
    "                        thoughts.append(f\"How much is {ent.text}?\")                \n",
    "                    else:\n",
    "                        thoughts.append(f\"What is {ent.text}? {ent.label_.capitalize()}?\")\n",
    "            new_toks = translate(p.text)\n",
    "            if new_toks != []:\n",
    "                thoughts.append(f\"{p.text}...\")\n",
    "                for tok in new_toks:\n",
    "                    if tok.lower not in str(thoughts).lower():\n",
    "                        thoughts.append(f\"{tok}?...\")\n",
    "    return(\" \".join(thoughts[:n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(stimulus, memory):\n",
    "    doc = make_spacy_doc(stimulus)\n",
    "    emoji = emote(doc, 1)\n",
    "    query = crappy_sort(doc, memory, 3)\n",
    "    return(f\"\\n----  {emoji} {query}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record(memory, outdir='output'):\n",
    "    now = str(date.today()) + \".md\"\n",
    "    outpath = Path(outdir)/now\n",
    "    with open(outpath, 'a') as f:\n",
    "        print(f'## {datetime.now()}', file=f)\n",
    "        print(' '.join(memory), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----  ðŸ˜ƒ What's happening?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  def crappy_sort(doc, memory, n=5):     if not doc._.phrases:         return \"...\"     thoughts = []     for p in doc._.phrases:          if p.text not in str(memory).lower():             for ent in doc.ents:                 if ent.text.lower() in p.text:                     if ent.label_ == \"PERSON\" or ent.label_ == \"NORP\" or ent.label_ == \"ORG\":                         thoughts.append(f\"Who is {ent.text}?\")                     elif ent.label_ == \"GPE\" or ent.label_ == \"FAC\" or ent.label_ == \"LOC\":                          thoughts.append(f\"Where is {ent.text}?\")                     elif ent.label_ == \"DATE\" or ent.label_ == \"TIME\":                          thoughts.append(f\"When is {ent.text}?\")                     elif ent.label_ == \"PERCENT\" or ent.label_ == \"MONEY\"or ent.label_ == \"QUANTITY\":                          thoughts.append(f\"How much is {ent.text}?\")                                     else:                         thoughts.append(f\"What is {ent.text}? {ent.label_.capitalize()}?\")             new_toks = translate(p.text)             if new_toks != []:                 thoughts.append(f\"{p.text}...\")                 for tok in new_toks:                     if tok.lower not in str(thoughts).lower():                         thoughts.append(f\"{tok}?...\")     return(\" \".join(thoughts[:n]))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'in <string>' requires string as left operand, not builtin_function_or_method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-dfcf8951519e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mstimulus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstimulus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrespond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstimulus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{stimulus}{response}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-172-b55fc28402ab>\u001b[0m in \u001b[0;36mrespond\u001b[0;34m(stimulus, memory)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_spacy_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstimulus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0memoji\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrappy_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n----  {emoji} {query}\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-189-0164f0c7f55c>\u001b[0m in \u001b[0;36mcrappy_sort\u001b[0;34m(doc, memory, n)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mthoughts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{p.text}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_toks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthoughts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                         \u001b[0mthoughts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{tok}?...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthoughts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'in <string>' requires string as left operand, not builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "print(\"----  ðŸ˜ƒ What's happening?\")\n",
    "stimulus = \"Hi\"\n",
    "memory = []\n",
    "while stimulus != \"\":\n",
    "    stimulus = input()\n",
    "    response = respond(stimulus, memory)\n",
    "    memory.append(f'{stimulus}{response}')\n",
    "    print(response)\n",
    "record(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trump campaign communications director Tim Murtaugh declined to comment on Giuliani's condition or whether Ellis has tested positive or plans to quarantine. He referred CNN to tweets by Trump and Ellis."
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "thoughts = []\n",
    "for p in doc._.phrases: \n",
    "    if p.text not in str(memory).lower():\n",
    "        for ent in doc.ents:\n",
    "            if ent.text.lower() in p.text:\n",
    "                if ent.label_ == \"PERSON\" or ent.label_ == \"NORP\" or ent.label_ == \"ORG\":\n",
    "                    thoughts.append(f\"Who is {ent.text}?\")\n",
    "                elif ent.label_ == \"GPE\" or ent.label_ == \"FAC\" or ent.label_ == \"LOC\": \n",
    "                    thoughts.append(f\"Where is {ent.text}?\")\n",
    "                elif ent.label_ == \"DATE\" or ent.label_ == \"TIME\": \n",
    "                    thoughts.append(f\"When is {ent.text}?\")\n",
    "                elif ent.label_ == \"PERCENT\" or ent.label_ == \"MONEY\"or ent.label_ == \"QUANTITY\": \n",
    "                    thoughts.append(f\"How much is {ent.text}?\")                \n",
    "                else:\n",
    "                    thoughts.append(f\"What is {ent.text}? {ent.label_.capitalize()}?\")\n",
    "        new_toks = translate(p.text)\n",
    "        if new_toks != []:\n",
    "            thoughts.append(f\"{p.text}...\")\n",
    "            for tok in new_toks:\n",
    "                if tok.lower() not in str(memory).lower() and tok.lower() not in str(thoughts).lower():\n",
    "                    thoughts.append(f\"{tok}?...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'she'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
